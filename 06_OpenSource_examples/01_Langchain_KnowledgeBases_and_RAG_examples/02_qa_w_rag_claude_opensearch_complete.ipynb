{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval Augmented Question & Answering with Amazon Bedrock using LangChain & Amazon OpenSearch\n",
    "\n",
    "> *This notebook should work well with the **`Data Science 3.0`** kernel in SageMaker Studio*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Context\n",
    "Previously we saw that the model told us how to to change the tire, however we had to manually provide it with the relevant data and provide the contex ourselves. We explored the approach to leverage the model availabe under Bedrock and ask questions based on it's knowledge learned during training as well as providing manual context. While that approach works with short documents or single-ton applications, it fails to scale to enterprise level question answering where there could be large enterprise documents which cannot all be fit into the prompt sent to the model. \n",
    "\n",
    "### Pattern\n",
    "We can improve upon this process by implementing an architecure called Retreival Augmented Generation (RAG). RAG retrieves data from outside the language model (non-parametric) and augments the prompts by adding the relevant retrieved data in context. \n",
    "\n",
    "In this notebook we explain how to approach the pattern of Question Answering to find and leverage the documents to provide answers to the user questions.\n",
    "\n",
    "### Challenges\n",
    "- How to manage large document(s) that exceed the token limit\n",
    "- How to find the document(s) relevant to the question being asked\n",
    "\n",
    "### Proposal\n",
    "To the above challenges, this notebook proposes the following strategy\n",
    "#### Prepare documents\n",
    "![Embeddings](../../imgs/Embeddings_lang.png)\n",
    "\n",
    "Before being able to answer the questions, the documents must be processed and a stored in a document store index\n",
    "- Load the documents\n",
    "- Process and split them into smaller chunks\n",
    "- Create a numerical vector representation of each chunk using Amazon Bedrock Titan Embeddings model\n",
    "- Create an index using the chunks and the corresponding embeddings\n",
    "#### Ask question\n",
    "![Question](../../imgs/Chatbot_lang.png)\n",
    "\n",
    "When the documents index is prepared, you are ready to ask the questions and relevant documents will be fetched based on the question being asked. Following steps will be executed.\n",
    "- Create an embedding of the input question\n",
    "- Compare the question embedding with the embeddings in the index\n",
    "- Fetch the (top N) relevant document chunks\n",
    "- Add those chunks as part of the context in the prompt\n",
    "- Send the prompt to the model under Amazon Bedrock\n",
    "- Get the contextual answer based on the documents retrieved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usecase\n",
    "#### Dataset\n",
    "To explain this architecture pattern we are using the documents from IRS. These documents explain topics such as:\n",
    "- Original Issue Discount (OID) Instruments\n",
    "- Reporting Cash Payments of Over $10,000 to IRS\n",
    "- Employer's Tax Guide\n",
    "\n",
    "#### Persona\n",
    "Let's assume a persona of a layman who doesn't have an understanding of how IRS works and if some actions have implications or not.\n",
    "\n",
    "The model will try to answer from the documents in easy language.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "In order to follow the RAG approach this notebook is using the LangChain framework where it has integrations with different services and tools that allow efficient building of patterns such as RAG. We will be using the following tools:\n",
    "\n",
    "- **LLM (Large Language Model)**: Anthropic Claude V2 available through Amazon Bedrock\n",
    "\n",
    "  This model will be used to understand the document chunks and provide an answer in human friendly manner.\n",
    "- **Embeddings Model**: Amazon Titan Embeddings available through Amazon Bedrock\n",
    "\n",
    "  This model will be used to generate a numerical representation of the textual documents\n",
    "- **Document Loader**: PDF Loader available through LangChain\n",
    "\n",
    "  This is the loader that can load the documents from a source, for the sake of this notebook we are loading the sample files from a local path. This could easily be replaced with a loader to load documents from enterprise internal systems.\n",
    "\n",
    "- **Vector Store**: OpenSearch available through LangChain\n",
    "\n",
    "  In this notebook we are using Amazon OpenSearch as a vector-store to store both the embeddings and the documents. \n",
    "- **Index**: VectorIndex\n",
    "\n",
    "  The index helps to compare the input embedding and the document embeddings to find relevant document\n",
    "- **Wrapper**: wraps index, vector store, embeddings model and the LLM to abstract away the logic from the user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Before running the rest of this notebook, you'll need to run the cells below to (ensure necessary libraries are installed and) connect to Bedrock.\n",
    "\n",
    "For more details on how the setup works and ⚠️ **whether you might need to make any changes**, refer to the [Bedrock boto3 setup notebook](../00_Intro/bedrock_boto3_setup.ipynb) notebook.\n",
    "\n",
    "In this notebook, we'll also need some extra dependencies:\n",
    "\n",
    "- [OpenSearch Python Client](https://pypi.org/project/opensearch-py/), to store vector embeddings\n",
    "- [PyPDF](https://pypi.org/project/pypdf/), for handling PDF files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting boto3>=1.28.57\n",
      "  Using cached boto3-1.34.120-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting awscli>=1.29.57\n",
      "  Using cached awscli-1.33.2-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting botocore>=1.31.57\n",
      "  Using cached botocore-1.34.120-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting jmespath<2.0.0,>=0.7.1 (from boto3>=1.28.57)\n",
      "  Using cached jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3>=1.28.57)\n",
      "  Using cached s3transfer-0.10.1-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting docutils<0.17,>=0.10 (from awscli>=1.29.57)\n",
      "  Using cached docutils-0.16-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting PyYAML<6.1,>=3.10 (from awscli>=1.29.57)\n",
      "  Using cached PyYAML-6.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting colorama<0.4.7,>=0.2.5 (from awscli>=1.29.57)\n",
      "  Using cached colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
      "Collecting rsa<4.8,>=3.1.2 (from awscli>=1.29.57)\n",
      "  Using cached rsa-4.7.2-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting python-dateutil<3.0.0,>=2.1 (from botocore>=1.31.57)\n",
      "  Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting urllib3!=2.2.0,<3,>=1.25.4 (from botocore>=1.31.57)\n",
      "  Using cached urllib3-2.2.1-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting six>=1.5 (from python-dateutil<3.0.0,>=2.1->botocore>=1.31.57)\n",
      "  Using cached six-1.16.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting pyasn1>=0.1.3 (from rsa<4.8,>=3.1.2->awscli>=1.29.57)\n",
      "  Using cached pyasn1-0.6.0-py2.py3-none-any.whl.metadata (8.3 kB)\n",
      "Using cached boto3-1.34.120-py3-none-any.whl (139 kB)\n",
      "Using cached awscli-1.33.2-py3-none-any.whl (4.5 MB)\n",
      "Using cached botocore-1.34.120-py3-none-any.whl (12.3 MB)\n",
      "Using cached colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Using cached docutils-0.16-py2.py3-none-any.whl (548 kB)\n",
      "Using cached jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "Using cached PyYAML-6.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (705 kB)\n",
      "Using cached rsa-4.7.2-py3-none-any.whl (34 kB)\n",
      "Using cached s3transfer-0.10.1-py3-none-any.whl (82 kB)\n",
      "Using cached urllib3-2.2.1-py3-none-any.whl (121 kB)\n",
      "Using cached pyasn1-0.6.0-py2.py3-none-any.whl (85 kB)\n",
      "Using cached six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Installing collected packages: urllib3, six, PyYAML, pyasn1, jmespath, docutils, colorama, rsa, python-dateutil, botocore, s3transfer, boto3, awscli\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 2.2.1\n",
      "    Uninstalling urllib3-2.2.1:\n",
      "      Successfully uninstalled urllib3-2.2.1\n",
      "  Attempting uninstall: six\n",
      "    Found existing installation: six 1.16.0\n",
      "    Uninstalling six-1.16.0:\n",
      "      Successfully uninstalled six-1.16.0\n",
      "  Attempting uninstall: PyYAML\n",
      "    Found existing installation: PyYAML 6.0.1\n",
      "    Uninstalling PyYAML-6.0.1:\n",
      "      Successfully uninstalled PyYAML-6.0.1\n",
      "  Attempting uninstall: pyasn1\n",
      "    Found existing installation: pyasn1 0.6.0\n",
      "    Uninstalling pyasn1-0.6.0:\n",
      "      Successfully uninstalled pyasn1-0.6.0\n",
      "  Attempting uninstall: jmespath\n",
      "    Found existing installation: jmespath 1.0.1\n",
      "    Uninstalling jmespath-1.0.1:\n",
      "      Successfully uninstalled jmespath-1.0.1\n",
      "  Attempting uninstall: docutils\n",
      "    Found existing installation: docutils 0.16\n",
      "    Uninstalling docutils-0.16:\n",
      "      Successfully uninstalled docutils-0.16\n",
      "  Attempting uninstall: colorama\n",
      "    Found existing installation: colorama 0.4.6\n",
      "    Uninstalling colorama-0.4.6:\n",
      "      Successfully uninstalled colorama-0.4.6\n",
      "  Attempting uninstall: rsa\n",
      "    Found existing installation: rsa 4.7.2\n",
      "    Uninstalling rsa-4.7.2:\n",
      "      Successfully uninstalled rsa-4.7.2\n",
      "  Attempting uninstall: python-dateutil\n",
      "    Found existing installation: python-dateutil 2.9.0.post0\n",
      "    Uninstalling python-dateutil-2.9.0.post0:\n",
      "      Successfully uninstalled python-dateutil-2.9.0.post0\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.34.120\n",
      "    Uninstalling botocore-1.34.120:\n",
      "      Successfully uninstalled botocore-1.34.120\n",
      "  Attempting uninstall: s3transfer\n",
      "    Found existing installation: s3transfer 0.10.1\n",
      "    Uninstalling s3transfer-0.10.1:\n",
      "      Successfully uninstalled s3transfer-0.10.1\n",
      "  Attempting uninstall: boto3\n",
      "    Found existing installation: boto3 1.34.120\n",
      "    Uninstalling boto3-1.34.120:\n",
      "      Successfully uninstalled boto3-1.34.120\n",
      "  Attempting uninstall: awscli\n",
      "    Found existing installation: awscli 1.33.2\n",
      "    Uninstalling awscli-1.33.2:\n",
      "      Successfully uninstalled awscli-1.33.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "opensearch-py 2.3.1 requires urllib3<2,>=1.21.1, but you have urllib3 2.2.1 which is incompatible.\n",
      "sagemaker-datawrangler 0.4.3 requires sagemaker-data-insights==0.4.0, but you have sagemaker-data-insights 0.3.3 which is incompatible.\n",
      "sphinx 7.2.6 requires docutils<0.21,>=0.18.1, but you have docutils 0.16 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed PyYAML-6.0.1 awscli-1.33.2 boto3-1.34.120 botocore-1.34.120 colorama-0.4.6 docutils-0.16 jmespath-1.0.1 pyasn1-0.6.0 python-dateutil-2.9.0.post0 rsa-4.7.2 s3transfer-0.10.1 six-1.16.0 urllib3-2.2.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --no-build-isolation --force-reinstall \\\n",
    "    \"boto3>=1.28.57\" \\\n",
    "    \"awscli>=1.29.57\" \\\n",
    "    \"botocore>=1.31.57\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opensearch-py==2.3.1 in /opt/conda/lib/python3.10/site-packages (2.3.1)\n",
      "Requirement already satisfied: apache-beam in /opt/conda/lib/python3.10/site-packages (2.56.0)\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.19.2)\n",
      "Requirement already satisfied: tiktoken in /opt/conda/lib/python3.10/site-packages (0.6.0)\n",
      "Collecting tiktoken\n",
      "  Using cached tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting urllib3<2,>=1.21.1 (from opensearch-py==2.3.1)\n",
      "  Using cached urllib3-1.26.18-py2.py3-none-any.whl.metadata (48 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.4.0 in /opt/conda/lib/python3.10/site-packages (from opensearch-py==2.3.1) (2.32.3)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from opensearch-py==2.3.1) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil in /opt/conda/lib/python3.10/site-packages (from opensearch-py==2.3.1) (2.9.0.post0)\n",
      "Requirement already satisfied: certifi>=2022.12.07 in /opt/conda/lib/python3.10/site-packages (from opensearch-py==2.3.1) (2024.2.2)\n",
      "Requirement already satisfied: crcmod<2.0,>=1.7 in /opt/conda/lib/python3.10/site-packages (from apache-beam) (1.7)\n",
      "Requirement already satisfied: orjson<4,>=3.9.7 in /opt/conda/lib/python3.10/site-packages (from apache-beam) (3.10.3)\n",
      "Requirement already satisfied: dill<0.3.2,>=0.3.1.1 in /opt/conda/lib/python3.10/site-packages (from apache-beam) (0.3.1.1)\n",
      "Requirement already satisfied: cloudpickle~=2.2.1 in /opt/conda/lib/python3.10/site-packages (from apache-beam) (2.2.1)\n",
      "Requirement already satisfied: fastavro<2,>=0.23.6 in /opt/conda/lib/python3.10/site-packages (from apache-beam) (1.9.4)\n",
      "Requirement already satisfied: fasteners<1.0,>=0.3 in /opt/conda/lib/python3.10/site-packages (from apache-beam) (0.19)\n",
      "Requirement already satisfied: grpcio!=1.48.0,!=1.59.*,!=1.60.*,!=1.61.*,!=1.62.0,!=1.62.1,<2,>=1.33.1 in /opt/conda/lib/python3.10/site-packages (from apache-beam) (1.64.1)\n",
      "Requirement already satisfied: hdfs<3.0.0,>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam) (2.7.3)\n",
      "Requirement already satisfied: httplib2<0.23.0,>=0.8 in /opt/conda/lib/python3.10/site-packages (from apache-beam) (0.22.0)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam) (4.21.1)\n",
      "Requirement already satisfied: jsonpickle<4.0.0,>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam) (3.0.4)\n",
      "Requirement already satisfied: numpy<1.27.0,>=1.14.3 in /opt/conda/lib/python3.10/site-packages (from apache-beam) (1.26.4)\n",
      "Requirement already satisfied: objsize<0.8.0,>=0.6.1 in /opt/conda/lib/python3.10/site-packages (from apache-beam) (0.7.0)\n",
      "Requirement already satisfied: packaging>=22.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam) (23.2)\n",
      "Requirement already satisfied: pymongo<5.0.0,>=3.8.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam) (4.7.3)\n",
      "Requirement already satisfied: proto-plus<2,>=1.7.1 in /opt/conda/lib/python3.10/site-packages (from apache-beam) (1.23.0)\n",
      "Requirement already satisfied: protobuf!=4.0.*,!=4.21.*,!=4.22.0,!=4.23.*,!=4.24.*,<4.26.0,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from apache-beam) (4.25.3)\n",
      "Requirement already satisfied: pydot<2,>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam) (1.4.2)\n",
      "Requirement already satisfied: pytz>=2018.3 in /opt/conda/lib/python3.10/site-packages (from apache-beam) (2024.1)\n",
      "Requirement already satisfied: redis<6,>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam) (5.0.4)\n",
      "Requirement already satisfied: regex>=2020.6.8 in /opt/conda/lib/python3.10/site-packages (from apache-beam) (2023.12.25)\n",
      "Requirement already satisfied: typing-extensions>=3.7.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam) (4.11.0)\n",
      "Requirement already satisfied: zstandard<1,>=0.18.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam) (0.22.0)\n",
      "Requirement already satisfied: pyarrow<15.0.0,>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam) (14.0.2)\n",
      "Requirement already satisfied: pyarrow-hotfix<1 in /opt/conda/lib/python3.10/site-packages (from apache-beam) (0.6)\n",
      "Requirement already satisfied: js2py<1,>=0.74 in /opt/conda/lib/python3.10/site-packages (from apache-beam) (0.74)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.13.4)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.1)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.9)\n",
      "Requirement already satisfied: fsspec<=2024.3.1,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.3.1,>=2023.1.0->datasets) (2024.3.1)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.23.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: docopt in /opt/conda/lib/python3.10/site-packages (from hdfs<3.0.0,>=2.1.0->apache-beam) (0.6.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /opt/conda/lib/python3.10/site-packages (from httplib2<0.23.0,>=0.8->apache-beam) (3.1.2)\n",
      "Requirement already satisfied: tzlocal>=1.2 in /opt/conda/lib/python3.10/site-packages (from js2py<1,>=0.74->apache-beam) (5.2)\n",
      "Requirement already satisfied: pyjsparser>=2.5.1 in /opt/conda/lib/python3.10/site-packages (from js2py<1,>=0.74->apache-beam) (2.7.1)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam) (0.34.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam) (0.18.0)\n",
      "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /opt/conda/lib/python3.10/site-packages (from pymongo<5.0.0,>=3.8.0->apache-beam) (2.6.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.4.0->opensearch-py==2.3.1) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.4.0->opensearch-py==2.3.1) (3.6)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\n",
      "Using cached tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "Using cached urllib3-1.26.18-py2.py3-none-any.whl (143 kB)\n",
      "Installing collected packages: urllib3, tiktoken\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 2.2.1\n",
      "    Uninstalling urllib3-2.2.1:\n",
      "      Successfully uninstalled urllib3-2.2.1\n",
      "  Attempting uninstall: tiktoken\n",
      "    Found existing installation: tiktoken 0.6.0\n",
      "    Uninstalling tiktoken-0.6.0:\n",
      "      Successfully uninstalled tiktoken-0.6.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "sphinx 7.2.6 requires docutils<0.21,>=0.18.1, but you have docutils 0.16 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed tiktoken-0.7.0 urllib3-1.26.18\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U opensearch-py==2.3.1  \\\n",
    "    apache-beam \\\n",
    "    datasets \\\n",
    "    tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: langchain-community in /opt/conda/lib/python3.10/site-packages (0.2.3)\n",
      "Requirement already satisfied: faiss-cpu==1.8.0 in /opt/conda/lib/python3.10/site-packages (1.8.0)\n",
      "Collecting tiktoken==0.6.0\n",
      "  Using cached tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: sqlalchemy==2.0.28 in /opt/conda/lib/python3.10/site-packages (2.0.28)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from faiss-cpu==1.8.0) (1.26.4)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/conda/lib/python3.10/site-packages (from tiktoken==0.6.0) (2023.12.25)\n",
      "Requirement already satisfied: requests>=2.26.0 in /opt/conda/lib/python3.10/site-packages (from tiktoken==0.6.0) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy==2.0.28) (4.11.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from sqlalchemy==2.0.28) (3.0.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (6.0.1)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (3.9.5)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (0.6.6)\n",
      "Requirement already satisfied: langchain<0.3.0,>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (0.2.2)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (0.2.4)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (0.1.73)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain-community) (8.2.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.21.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from langchain<0.3.0,>=0.2.0->langchain-community) (0.2.1)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain<0.3.0,>=0.2.0->langchain-community) (2.7.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.0->langchain-community) (1.33)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.0->langchain-community) (23.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.0->langchain-community) (3.10.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken==0.6.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken==0.6.0) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken==0.6.0) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken==0.6.0) (2024.2.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.0->langchain-community) (2.4)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.0->langchain-community) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.1 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.0->langchain-community) (2.18.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "Using cached tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
      "Installing collected packages: tiktoken\n",
      "  Attempting uninstall: tiktoken\n",
      "    Found existing installation: tiktoken 0.7.0\n",
      "    Uninstalling tiktoken-0.7.0:\n",
      "      Successfully uninstalled tiktoken-0.7.0\n",
      "Successfully installed tiktoken-0.6.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain>=0.1.11\n",
    "%pip install pypdf>=4.1.0\n",
    "%pip install langchain-community faiss-cpu==1.8.0 tiktoken==0.6.0 sqlalchemy==2.0.28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "from io import StringIO\n",
    "import sys\n",
    "import textwrap\n",
    "import os\n",
    "from typing import Optional\n",
    "\n",
    "# External Dependencies:\n",
    "import boto3\n",
    "from botocore.config import Config\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def print_ww(*args, width: int = 100, **kwargs):\n",
    "    \"\"\"Like print(), but wraps output to `width` characters (default 100)\"\"\"\n",
    "    buffer = StringIO()\n",
    "    try:\n",
    "        _stdout = sys.stdout\n",
    "        sys.stdout = buffer\n",
    "        print(*args, **kwargs)\n",
    "        output = buffer.getvalue()\n",
    "    finally:\n",
    "        sys.stdout = _stdout\n",
    "    for line in output.splitlines():\n",
    "        print(\"\\n\".join(textwrap.wrap(line, width=width)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import boto3\n",
    "import botocore\n",
    "\n",
    "boto3_bedrock = boto3.client('bedrock-runtime')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure langchain\n",
    "\n",
    "We begin with instantiating the LLM and the Embeddings model. Here we are using Anthropic Claude for text generation and Amazon Titan for text embedding.\n",
    "\n",
    "Note: It is possible to choose other models available with Bedrock. You can replace the `model_id` as follows to change the model.\n",
    "\n",
    "`llm = Bedrock(model_id=\"amazon.titan-tg1-large\")`\n",
    "\n",
    "Available model IDs include:\n",
    "\n",
    "- `ai21.j2-ultra-v1`\n",
    "- `ai21.j2-mid-v1`\n",
    "- `amazon.titan-embed-text-v1`\n",
    "- `amazon.titan-text-express-v1`\n",
    "- `anthropic.claude-v1`\n",
    "- `anthropic.claude-v2`\n",
    "- `anthropic.claude-instant-v1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The class `Bedrock` was deprecated in LangChain 0.0.34 and will be removed in 0.3. An updated version of the class exists in the langchain-aws package and should be used instead. To use it run `pip install -U langchain-aws` and import as `from langchain_aws import BedrockLLM`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "# We will be using the Titan Embeddings Model to generate our Embeddings.\n",
    "from langchain.embeddings import BedrockEmbeddings\n",
    "from langchain.llms.bedrock import Bedrock\n",
    "from langchain.load.dump import dumps\n",
    "\n",
    "# - create the Anthropic Model\n",
    "llm = Bedrock(\n",
    "    model_id=\"anthropic.claude-v2\", client=boto3_bedrock, model_kwargs={\"max_tokens_to_sample\": 200}\n",
    ")\n",
    "bedrock_embeddings = BedrockEmbeddings(client=boto3_bedrock)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "Let's first download some of the files to build our document store. For this example we will be using public IRS documents from [here](https://www.irs.gov/publications)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from urllib.request import urlretrieve\n",
    "\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "files = [\n",
    "    \"https://www.irs.gov/pub/irs-pdf/p1544.pdf\",\n",
    "    \"https://www.irs.gov/pub/irs-pdf/p15.pdf\",\n",
    "    \"https://www.irs.gov/pub/irs-pdf/p1212.pdf\",\n",
    "]\n",
    "for url in files:\n",
    "    file_path = os.path.join(\"data\", url.rpartition(\"/\")[2])\n",
    "    urlretrieve(url, file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After downloading we can load the documents with the help of [DirectoryLoader from PyPDF available under LangChain](https://python.langchain.com/en/latest/reference/modules/document_loaders.html) and splitting them into smaller chunks.\n",
    "\n",
    "Note: The retrieved document/text should be large enough to contain enough information to answer a question; but small enough to fit into the LLM prompt. Also the embeddings model has a limit of the length of input tokens limited to 8k tokens, which roughly translates to ~32000 characters. For the sake of this use-case we are creating chunks of roughly 2000 characters with an overlap of 200 characters using [RecursiveCharacterTextSplitter](https://python.langchain.com/en/latest/modules/indexes/text_splitters/examples/recursive_text_splitter.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import PyPDFLoader, PyPDFDirectoryLoader\n",
    "\n",
    "loader = PyPDFDirectoryLoader(\"./data/\")\n",
    "\n",
    "documents = loader.load()\n",
    "# - in our testing Character split works better with this PDF data set\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    # Set a really small chunk size, just to show.\n",
    "    chunk_size=2000,\n",
    "    chunk_overlap=200,\n",
    ")\n",
    "docs = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average length among 81 documents loaded is 5889 characters.\n",
      "After the split we have 300 documents more than the original 81.\n",
      "Average length among 300 documents (after split) is 1718 characters.\n"
     ]
    }
   ],
   "source": [
    "avg_doc_length = lambda documents: sum([len(doc.page_content) for doc in documents]) // len(\n",
    "    documents\n",
    ")\n",
    "avg_char_count_pre = avg_doc_length(documents)\n",
    "avg_char_count_post = avg_doc_length(docs)\n",
    "print(f\"Average length among {len(documents)} documents loaded is {avg_char_count_pre} characters.\")\n",
    "print(f\"After the split we have {len(docs)} documents more than the original {len(documents)}.\")\n",
    "print(\n",
    "    f\"Average length among {len(docs)} documents (after split) is {avg_char_count_post} characters.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding model Id : amazon.titan-embed-text-v1\n",
      "Sample embedding of a document chunk:  [ 0.3359375  -0.07910156 -0.33203125 ...  0.08837891 -0.29882812\n",
      " -0.23535156]\n",
      "Size of the embedding:  (1536,)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    \n",
    "    sample_embedding = np.array(bedrock_embeddings.embed_query(docs[0].page_content))\n",
    "    modelId = bedrock_embeddings.model_id\n",
    "    print(\"Embedding model Id :\", modelId)\n",
    "    print(\"Sample embedding of a document chunk: \", sample_embedding)\n",
    "    print(\"Size of the embedding: \", sample_embedding.shape)\n",
    "\n",
    "except ValueError as error:\n",
    "    if  \"AccessDeniedException\" in str(error):\n",
    "        print(f\"\\x1b[41m{error}\\\n",
    "        \\nTo troubeshoot this issue please refer to the following resources.\\\n",
    "         \\nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/troubleshoot_access-denied.html\\\n",
    "         \\nhttps://docs.aws.amazon.com/bedrock/latest/userguide/security-iam.html\\x1b[0m\\n\")      \n",
    "        class StopExecution(ValueError):\n",
    "            def _render_traceback_(self):\n",
    "                pass\n",
    "        raise StopExecution        \n",
    "    else:\n",
    "        raise error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the similar pattern embeddings could be generated for the entire corpus and stored in a vector store.\n",
    "\n",
    "Firt of all we have to create a vector store. In this workshop we will use ***Amazon OpenSearch serverless.***\n",
    "\n",
    "Amazon OpenSearch Serverless is a serverless option in Amazon OpenSearch Service. As a developer, you can use OpenSearch Serverless to run petabyte-scale workloads without configuring, managing, and scaling OpenSearch clusters. You get the same interactive millisecond response times as OpenSearch Service with the simplicity of a serverless environment. Pay only for what you use by automatically scaling resources to provide the right amount of capacity for your application—without impacting data ingestion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import time\n",
    "vector_store_name = 'bedrock-workshop-rag'\n",
    "index_name = \"bedrock-workshop-rag-index\"\n",
    "encryption_policy_name = \"bedrock-workshop-rag-sp\"\n",
    "network_policy_name = \"bedrock-workshop-rag-np\"\n",
    "access_policy_name = 'bedrock-workshop-rag-ap'\n",
    "identity = boto3.client('sts').get_caller_identity()['Arn']\n",
    "\n",
    "aoss_client = boto3.client('opensearchserverless')\n",
    "\n",
    "security_policy = aoss_client.create_security_policy(\n",
    "    name = encryption_policy_name,\n",
    "    policy = json.dumps(\n",
    "        {\n",
    "            'Rules': [{'Resource': ['collection/' + vector_store_name],\n",
    "            'ResourceType': 'collection'}],\n",
    "            'AWSOwnedKey': True\n",
    "        }),\n",
    "    type = 'encryption'\n",
    ")\n",
    "\n",
    "network_policy = aoss_client.create_security_policy(\n",
    "    name = network_policy_name,\n",
    "    policy = json.dumps(\n",
    "        [\n",
    "            {'Rules': [{'Resource': ['collection/' + vector_store_name],\n",
    "            'ResourceType': 'collection'}],\n",
    "            'AllowFromPublic': True}\n",
    "        ]),\n",
    "    type = 'network'\n",
    ")\n",
    "\n",
    "collection = aoss_client.create_collection(name=vector_store_name,type='VECTORSEARCH')\n",
    "\n",
    "while True:\n",
    "    status = aoss_client.list_collections(collectionFilters={'name':vector_store_name})['collectionSummaries'][0]['status']\n",
    "    if status in ('ACTIVE', 'FAILED'): break\n",
    "    time.sleep(10)\n",
    "\n",
    "access_policy = aoss_client.create_access_policy(\n",
    "    name = access_policy_name,\n",
    "    policy = json.dumps(\n",
    "        [\n",
    "            {\n",
    "                'Rules': [\n",
    "                    {\n",
    "                        'Resource': ['collection/' + vector_store_name],\n",
    "                        'Permission': [\n",
    "                            'aoss:CreateCollectionItems',\n",
    "                            'aoss:DeleteCollectionItems',\n",
    "                            'aoss:UpdateCollectionItems',\n",
    "                            'aoss:DescribeCollectionItems'],\n",
    "                        'ResourceType': 'collection'\n",
    "                    },\n",
    "                    {\n",
    "                        'Resource': ['index/' + vector_store_name + '/*'],\n",
    "                        'Permission': [\n",
    "                            'aoss:CreateIndex',\n",
    "                            'aoss:DeleteIndex',\n",
    "                            'aoss:UpdateIndex',\n",
    "                            'aoss:DescribeIndex',\n",
    "                            'aoss:ReadDocument',\n",
    "                            'aoss:WriteDocument'],\n",
    "                        'ResourceType': 'index'\n",
    "                    }],\n",
    "                'Principal': [identity],\n",
    "                'Description': 'Easy data policy'}\n",
    "        ]),\n",
    "    type = 'data'\n",
    ")\n",
    "\n",
    "host = collection['createCollectionDetail']['id'] + '.' + os.environ.get(\"AWS_DEFAULT_REGION\", None) + '.aoss.amazonaws.com:443'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to inject our documents into vector store. This can be easily done using [OpenSearch](https://python.langchain.com/docs/integrations/vectorstores/opensearch) implementation inside [LangChain](https://python.langchain.com/en/latest/modules/indexes/vectorstores/examples/faiss.html) which takes  input the embeddings model and the documents to create the entire vector store. Using the Index Wrapper we can abstract away most of the heavy lifting such as creating the prompt, getting embeddings of the query, sampling the relevant documents and calling the LLM. [VectorStoreIndexWrapper](https://python.langchain.com/en/latest/modules/indexes/getting_started.html#one-line-index-creation) helps us with that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from opensearchpy import OpenSearch, RequestsHttpConnection, AWSV4SignerAuth\n",
    "from langchain.vectorstores import OpenSearchVectorSearch\n",
    "\n",
    "service = 'aoss'\n",
    "credentials = boto3.Session().get_credentials()\n",
    "auth = AWSV4SignerAuth(credentials, os.environ.get(\"AWS_DEFAULT_REGION\", 'us-east-1'), service)\n",
    "\n",
    "docsearch = OpenSearchVectorSearch.from_documents(\n",
    "    docs,\n",
    "    bedrock_embeddings,\n",
    "    opensearch_url=host,\n",
    "    http_auth=auth,\n",
    "    timeout = 100,\n",
    "    use_ssl = True,\n",
    "    verify_certs = True,\n",
    "    connection_class = RequestsHttpConnection,\n",
    "    index_name=index_name,\n",
    "    engine=\"faiss\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangChain Vector Store and Querying"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### We can use the similarity search method to make a query and return the chunks of text without any LLM generating the response.\n",
    "\n",
    "It takes a few seconds to make documents availible in index. If you will get an empty output in a next cell, just wait a little bit and retry. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "query = \"Is it possible that I get sentenced to jail due to failure in filings?\"\n",
    "\n",
    "results = docsearch.similarity_search(query, k=3)  # our search query  # return 3 most relevant docs\n",
    "print(dumps(results, pretty=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All of these are relevant results, telling us that the retrieval component of our systems is functioning. The next step is adding our LLM to generatively answer our question using the information provided in these retrieved contexts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generative Question Answering\n",
    "\n",
    "In generative question-answering (GQA), we pass our question to the Claude-2 but instruct it to base the answer on the information returned from our knowledge base. We can do this in LangChain easily using the RetrievalQA chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=docsearch.as_retriever())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let’s try this with our earlier query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" Based on the information provided in the context, it does not seem likely that you would be sentenced to jail solely for failure to properly file tax forms like Form 8300 or failure to pay taxes on time. Some key points:\\n\\n- The penalties described for late filing, incomplete filing, or failure to pay taxes on time are monetary penalties, interest charges, and potential trust fund recovery penalties. Jail time is not mentioned as a penalty for these filing issues.\\n\\n- The context mentions that criminal penalties may apply if you don't comply with special bank deposit requirements for a government trust account after receiving written notice from the IRS. But there is no indication this has occurred. \\n\\n- The trust fund recovery penalty, which can be imposed if payroll taxes are not paid, is a monetary penalty equal to 100% of the unpaid tax, not jail time. \\n\\n- The context does not describe any intentional tax evasion, fraud, or other criminal tax offenses that could potentially lead to jail\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa.run(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’re still not entirely protected from convincing yet false hallucinations by the model, they can happen, and it’s unlikely that we can eliminate the problem completely. However, we can do more to improve our trust in the answers provided.\n",
    "\n",
    "An effective way of doing this is by adding citations to the response, allowing a user to see where the information is coming from. We can do this using a slightly different version of the RetrievalQA chain called RetrievalQAWithSourcesChain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "\n",
    "qa_with_sources = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=docsearch.as_retriever(search_kwargs={'k': 3}),return_source_documents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"query\": \"Is it possible that I get sentenced to jail due to failure in filings?\",\n",
      "  \"result\": \" Based on the context provided, it seems possible you could face criminal penalties or jail time for certain failures related to filing tax forms or complying with special IRS deposit requirements. A few key points:\\n\\n- The passage mentions that willful failure to collect, account for, or pay over trust fund taxes could result in criminal penalties. Trust fund taxes refer to income tax, Social Security tax, and Medicare tax withheld from employees' wages. Willfully not paying over these withheld taxes could potentially lead to jail time.\\n\\n- It also warns that criminal penalties may apply if you don't comply with special bank deposit requirements for a special trust account for the U.S. Government. This refers to separate accounting the IRS may require in certain situations. \\n\\n- In general, criminal tax violations require willful or intentional conduct, not just mistakes or oversight. But the consequences can be severe.\\n\\nSo in summary, yes, it seems in certain situations of intentional tax violations related to withholding\",\n",
      "  \"source_documents\": [\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"document\",\n",
      "        \"Document\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"page_content\": \"clerks of federal or state courts are discussed \\nlater under Bail received by court clerks.\\nHowever, you do not have to file Form 8300 \\nif the transaction is not related to your trade or \\nbusiness. For example, if you own a jewelry \\nstore and sell your personal automobile for \\nmore than $10,000 in cash, you would not sub-\\nmit a Form 8300 for that transaction.\\nTransaction defined.  A \\u201ctransaction\\u201d occurs \\nwhen:\\nGoods, services, or property are sold;\\nProperty is rented;\\nCash is exchanged for other cash;\\nA contribution is made to a trust or escrow \\naccount;\\nA loan is made or repaid; or\\nCash is converted to a negotiable instru-\\nment, such as a check or a bond.\\nPerson defined.  A \\u201cperson\\u201d includes an indi-\\nvidual, a company, a corporation, a partnership, \\nan association, a trust, or an estate.\\nExempt organizations, including employee \\nplans, are also \\u201cpersons.\\u201d However, exempt or-\\nganizations do not have to file Form 8300 for a \\nmore-than-$10,000 charitable cash contribution \\nthey receive since it is not received in the \\ncourse of a trade or business.\\nForeign transactions.  You do not have to file \\nForm 8300 if the entire transaction (including \\nthe receipt of cash) takes place outside of:\\nThe 50 states,\\nThe District of Columbia,\\nPuerto Rico, or\\nA possession or territory of the United \\nStates.\\nHowever, you must file Form 8300 if any part of \\nthe transaction (including the receipt of cash) \\noccurs in Puerto Rico or a possession or terri-\\ntory of the United States and you are subject to \\nthe Internal Revenue Code.\\nBail received by court clerks.  Any clerk of a \\nfederal or state court who receives more than \\n$10,000 in cash as bail for an individual \\ncharged with any of the following criminal offen-\\nses must file Form 8300:\\n1.Any federal offense involving a controlled \\nsubstance,\\n2.Racketeering,\\n3.Money laundering, and\\n4.Any state offense substantially similar to \\n(1), (2), or (3) above.\\nFor more information about the rules that apply\",\n",
      "        \"metadata\": {\n",
      "          \"source\": \"data/p1544.pdf\",\n",
      "          \"page\": 1\n",
      "        },\n",
      "        \"type\": \"Document\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"document\",\n",
      "        \"Document\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"page_content\": \"funds.\\nWillfully  means voluntarily, consciously, and intention-\\nally. A responsible person acts willfully if the person knows \\nthe required actions of collecting, accounting for, or paying \\nover trust fund taxes aren't taking place, or recklessly dis-\\nregards obvious and known risks to the government's right \\nto receive trust fund taxes.\\nSeparate accounting when deposits aren't made or \\nwithheld taxes aren't paid.  Separate accounting may \\nbe required if you don't pay over withheld employee social \\nsecurity, Medicare, or income taxes; deposit required \\ntaxes; make required payments; or file tax returns. In this \\ncase, you would receive written notice from the IRS requir-\\ning you to deposit taxes into a special trust account for the \\nU.S. Government.\\nY ou may be charged with criminal penalties if you \\ndon't comply with the special bank deposit re-\\nquirements for the special trust account for the \\nU.S. Government.\\n\\u201cAveraged\\u201d FTD penalty.  The IRS may assess an \\n\\\"averaged\\\" FTD penalty of 2% to 10% if you\\u2019re a monthly \\nschedule depositor and didn't properly complete Form \\n941, line 16; Form 943, line 17; Form 944, line 13; or Form \\n945, line 7, when your tax liability shown on Form 941, \\nline 12; Form 943, line 13; Form 944, line 9; or Form 945, \\nline 3, equaled or exceeded $2,500.\\nThe IRS may also assess an \\\"averaged\\\" FTD penalty of \\n2% to 10% if you\\u2019re a semiweekly schedule depositor and \\nyour tax liability shown on Form 941, line 12; Form 943, \\nline 13; Form 944, line 9; or Form 945, line 3, equaled or \\nexceeded $2,500 and you:\\n\\u2022Completed Form 941, line 16, instead of Schedule B \\n(Form 941); Form 943, line 17, instead of Form 943-A; \\nForm 944, line 13, instead of Form 945-A; or Form \\n945, line 7, instead of Form 945-A;\\n\\u2022Failed to attach a properly completed Schedule B \\n(Form 941); Form 943-A, or Form 945-A, as applica-\\nble; or\\n\\u2022Improperly completed Schedule B (Form 941), Form \\n943-A, or Form 945-A by, for example, entering tax de-\",\n",
      "        \"metadata\": {\n",
      "          \"source\": \"data/p15.pdf\",\n",
      "          \"page\": 34\n",
      "        },\n",
      "        \"type\": \"Document\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"document\",\n",
      "        \"Document\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"page_content\": \"ure-to- pay (FTP) penalty of 0.5% per month of the amount \\nof tax. For individual filers only, the FTP penalty is reduced \\nfrom 0.5% per month to 0.25% per month if an installment \\nagreement is in effect. Y ou must have filed your return on \\nor before the due date of the return to qualify for the re-\\nduced penalty. The maximum amount of the FTP penalty \\nis also 25% of the tax due. If both penalties apply in any \\nmonth, the FTF penalty is reduced by the amount of the \\nFTP penalty. The penalties won't be charged if you have \\nreasonable cause for failing to file or pay. If you receive a \\npenalty notice, you can provide an explanation of why you \\nbelieve reasonable cause exists.\\nNote.  In addition to any penalties, interest accrues \\nfrom the due date of the tax on any unpaid balance.\\nIf income, social security, or Medicare taxes that must \\nbe withheld aren't withheld or aren't paid, you may be per-\\nsonally liable for the trust fund recovery penalty. See T rust \\nfund recovery penalty  in section 11.\\nGenerally, the use of a third -party payer, such as a PSP \\nor reporting agent, doesn't relieve an employer of the re-\\nsponsibility to ensure tax returns are filed and all taxes are \\npaid or deposited correctly and on time. However, see \\nCertified professional employer organization (CPEO) , in \\nsection 16, for an exception.\\nDon't file more than one return per return period. \\nEmployers with multiple locations or divisions must file \\nonly one Form 941 per quarter or one Form 944 per year. \\nAn agricultural employer must file only one Form 943 per \\nyear. A payer of nonpayroll payments that withheld federal \\nincome tax or backup withholding must file only one Form \\n945 per year. Filing more than one return may result in \\nprocessing delays and may require correspondence be-\\ntween you and the IRS. For information on making adjust-\\nments to previously filed returns, see section 13 .\\nReminders about filing. \\n\\u2022Don't report more than 1 calendar quarter on a Form \\n941.\",\n",
      "        \"metadata\": {\n",
      "          \"source\": \"data/p15.pdf\",\n",
      "          \"page\": 36\n",
      "        },\n",
      "        \"type\": \"Document\"\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(dumps(qa_with_sources(query), pretty=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we have answered the question being asked but also included the source of this information being used by the LLM.\n",
    "\n",
    "#### We’ve learned how to ground Large Language Models with source knowledge by using a vector database as our knowledge base. Using this, we can encourage accuracy in our LLM’s responses, keep source knowledge up to date, and improve trust in our system by providing citations with every answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this embedding of the query to then fetch relevant documents.\n",
    "Now our query is represented as embeddings we can do a similarity search of our query against our data store providing us with the most relevant information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customisable option\n",
    "In the above scenario you explored the quick and easy way to get a context-aware answer to your question. Now let's have a look at a more customizable option with the helpf of [RetrievalQA](https://python.langchain.com/en/latest/modules/chains/index_examples/vector_db_qa.html) where you can customize how the documents fetched should be added to prompt using `chain_type` parameter. Also, if you want to control how many relevant documents should be retrieved then change the `k` parameter in the cell below to see different outputs. In many scenarios you might want to know which were the source documents that the LLM used to generate the answer, you can get those documents in the output using `return_source_documents` which returns the documents that are added to the context of the LLM prompt. `RetrievalQA` also allows you to provide a custom [prompt template](https://python.langchain.com/en/latest/modules/prompts/prompt_templates/getting_started.html) which can be specific to the model.\n",
    "\n",
    "Note: In this example we are using Anthropic Claude as the LLM under Amazon Bedrock, this particular model performs best if the inputs are provided under `Human:` and the model is requested to generate an output after `Assistant:`. In the cell below you see an example of how to control the prompt such that the LLM stays grounded and doesn't answer outside the context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Sulla base delle informazioni fornite, è possibile che si venga condannati al carcere per\n",
      "inadempienze nella presentazione di documenti fiscali, in particolare se si tratta di evasione\n",
      "fiscale intenzionale. Tuttavia, ci possono essere molti fattori da considerare, come la gravità del\n",
      "reato, se è la prima infrazione, e se si collabora con le autorità. In generale, è importante\n",
      "consultare un avvocato fiscale se si hanno preoccupazioni su possibili conseguenze penali per\n",
      "questioni fiscali.\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = \"\"\"Human: Use the following pieces of context to provide a concise answer in Italian to the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Assistant:\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n",
    "\n",
    "qa_prompt = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=docsearch.as_retriever(),\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": PROMPT},\n",
    ")\n",
    "query = \"Is it possible that I get sentenced to jail due to failure in filings?\"\n",
    "result = qa_prompt({\"query\": query})\n",
    "print_ww(result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"query\": \"Is it possible that I get sentenced to jail due to failure in filings?\",\n",
      "  \"result\": \" Sulla base delle informazioni fornite, \\u00e8 possibile che si venga condannati al carcere per inadempienze nella presentazione di documenti fiscali, in particolare se si tratta di evasione fiscale intenzionale. Tuttavia, ci possono essere molti fattori da considerare, come la gravit\\u00e0 del reato, se \\u00e8 la prima infrazione, e se si collabora con le autorit\\u00e0. In generale, \\u00e8 importante consultare un avvocato fiscale se si hanno preoccupazioni su possibili conseguenze penali per questioni fiscali.\",\n",
      "  \"source_documents\": [\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"document\",\n",
      "        \"Document\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"page_content\": \"clerks of federal or state courts are discussed \\nlater under Bail received by court clerks.\\nHowever, you do not have to file Form 8300 \\nif the transaction is not related to your trade or \\nbusiness. For example, if you own a jewelry \\nstore and sell your personal automobile for \\nmore than $10,000 in cash, you would not sub-\\nmit a Form 8300 for that transaction.\\nTransaction defined.  A \\u201ctransaction\\u201d occurs \\nwhen:\\nGoods, services, or property are sold;\\nProperty is rented;\\nCash is exchanged for other cash;\\nA contribution is made to a trust or escrow \\naccount;\\nA loan is made or repaid; or\\nCash is converted to a negotiable instru-\\nment, such as a check or a bond.\\nPerson defined.  A \\u201cperson\\u201d includes an indi-\\nvidual, a company, a corporation, a partnership, \\nan association, a trust, or an estate.\\nExempt organizations, including employee \\nplans, are also \\u201cpersons.\\u201d However, exempt or-\\nganizations do not have to file Form 8300 for a \\nmore-than-$10,000 charitable cash contribution \\nthey receive since it is not received in the \\ncourse of a trade or business.\\nForeign transactions.  You do not have to file \\nForm 8300 if the entire transaction (including \\nthe receipt of cash) takes place outside of:\\nThe 50 states,\\nThe District of Columbia,\\nPuerto Rico, or\\nA possession or territory of the United \\nStates.\\nHowever, you must file Form 8300 if any part of \\nthe transaction (including the receipt of cash) \\noccurs in Puerto Rico or a possession or terri-\\ntory of the United States and you are subject to \\nthe Internal Revenue Code.\\nBail received by court clerks.  Any clerk of a \\nfederal or state court who receives more than \\n$10,000 in cash as bail for an individual \\ncharged with any of the following criminal offen-\\nses must file Form 8300:\\n1.Any federal offense involving a controlled \\nsubstance,\\n2.Racketeering,\\n3.Money laundering, and\\n4.Any state offense substantially similar to \\n(1), (2), or (3) above.\\nFor more information about the rules that apply\",\n",
      "        \"metadata\": {\n",
      "          \"source\": \"data/p1544.pdf\",\n",
      "          \"page\": 1\n",
      "        },\n",
      "        \"type\": \"Document\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"document\",\n",
      "        \"Document\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"page_content\": \"funds.\\nWillfully  means voluntarily, consciously, and intention-\\nally. A responsible person acts willfully if the person knows \\nthe required actions of collecting, accounting for, or paying \\nover trust fund taxes aren't taking place, or recklessly dis-\\nregards obvious and known risks to the government's right \\nto receive trust fund taxes.\\nSeparate accounting when deposits aren't made or \\nwithheld taxes aren't paid.  Separate accounting may \\nbe required if you don't pay over withheld employee social \\nsecurity, Medicare, or income taxes; deposit required \\ntaxes; make required payments; or file tax returns. In this \\ncase, you would receive written notice from the IRS requir-\\ning you to deposit taxes into a special trust account for the \\nU.S. Government.\\nY ou may be charged with criminal penalties if you \\ndon't comply with the special bank deposit re-\\nquirements for the special trust account for the \\nU.S. Government.\\n\\u201cAveraged\\u201d FTD penalty.  The IRS may assess an \\n\\\"averaged\\\" FTD penalty of 2% to 10% if you\\u2019re a monthly \\nschedule depositor and didn't properly complete Form \\n941, line 16; Form 943, line 17; Form 944, line 13; or Form \\n945, line 7, when your tax liability shown on Form 941, \\nline 12; Form 943, line 13; Form 944, line 9; or Form 945, \\nline 3, equaled or exceeded $2,500.\\nThe IRS may also assess an \\\"averaged\\\" FTD penalty of \\n2% to 10% if you\\u2019re a semiweekly schedule depositor and \\nyour tax liability shown on Form 941, line 12; Form 943, \\nline 13; Form 944, line 9; or Form 945, line 3, equaled or \\nexceeded $2,500 and you:\\n\\u2022Completed Form 941, line 16, instead of Schedule B \\n(Form 941); Form 943, line 17, instead of Form 943-A; \\nForm 944, line 13, instead of Form 945-A; or Form \\n945, line 7, instead of Form 945-A;\\n\\u2022Failed to attach a properly completed Schedule B \\n(Form 941); Form 943-A, or Form 945-A, as applica-\\nble; or\\n\\u2022Improperly completed Schedule B (Form 941), Form \\n943-A, or Form 945-A by, for example, entering tax de-\",\n",
      "        \"metadata\": {\n",
      "          \"source\": \"data/p15.pdf\",\n",
      "          \"page\": 34\n",
      "        },\n",
      "        \"type\": \"Document\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"document\",\n",
      "        \"Document\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"page_content\": \"ure-to- pay (FTP) penalty of 0.5% per month of the amount \\nof tax. For individual filers only, the FTP penalty is reduced \\nfrom 0.5% per month to 0.25% per month if an installment \\nagreement is in effect. Y ou must have filed your return on \\nor before the due date of the return to qualify for the re-\\nduced penalty. The maximum amount of the FTP penalty \\nis also 25% of the tax due. If both penalties apply in any \\nmonth, the FTF penalty is reduced by the amount of the \\nFTP penalty. The penalties won't be charged if you have \\nreasonable cause for failing to file or pay. If you receive a \\npenalty notice, you can provide an explanation of why you \\nbelieve reasonable cause exists.\\nNote.  In addition to any penalties, interest accrues \\nfrom the due date of the tax on any unpaid balance.\\nIf income, social security, or Medicare taxes that must \\nbe withheld aren't withheld or aren't paid, you may be per-\\nsonally liable for the trust fund recovery penalty. See T rust \\nfund recovery penalty  in section 11.\\nGenerally, the use of a third -party payer, such as a PSP \\nor reporting agent, doesn't relieve an employer of the re-\\nsponsibility to ensure tax returns are filed and all taxes are \\npaid or deposited correctly and on time. However, see \\nCertified professional employer organization (CPEO) , in \\nsection 16, for an exception.\\nDon't file more than one return per return period. \\nEmployers with multiple locations or divisions must file \\nonly one Form 941 per quarter or one Form 944 per year. \\nAn agricultural employer must file only one Form 943 per \\nyear. A payer of nonpayroll payments that withheld federal \\nincome tax or backup withholding must file only one Form \\n945 per year. Filing more than one return may result in \\nprocessing delays and may require correspondence be-\\ntween you and the IRS. For information on making adjust-\\nments to previously filed returns, see section 13 .\\nReminders about filing. \\n\\u2022Don't report more than 1 calendar quarter on a Form \\n941.\",\n",
      "        \"metadata\": {\n",
      "          \"source\": \"data/p15.pdf\",\n",
      "          \"page\": 36\n",
      "        },\n",
      "        \"type\": \"Document\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"lc\": 1,\n",
      "      \"type\": \"constructor\",\n",
      "      \"id\": [\n",
      "        \"langchain\",\n",
      "        \"schema\",\n",
      "        \"document\",\n",
      "        \"Document\"\n",
      "      ],\n",
      "      \"kwargs\": {\n",
      "        \"page_content\": \"irb01-50.pdf .\\nExample.  Cedar, Inc., is required to make a deposit of \\n$1,000 on February 15 and $1,500 on March 15. It doesn't \\nmake the deposit on February 15. On March 15, Cedar, \\nInc., deposits $2,000. Under the deposits rule, which ap-\\nplies deposits to the most recent tax liability, $1,500 of the \\ndeposit is applied to the March 15 deposit and the remain-\\ning $500 is applied to the February deposit. Accordingly, \\n$500 of the February 15 liability remains undeposited. The \\npenalty on this underdeposit will apply as explained ear-\\nlier.\\nTrust fund recovery penalty.  If federal income, social \\nsecurity, or Medicare taxes that must be withheld (that is, \\ntrust fund taxes) aren't withheld or aren't deposited or paid \\nto the U.S. T reasury, the trust fund recovery penalty may \\napply. The penalty is 100% of the unpaid trust fund tax. If \\nthese unpaid taxes can't be immediately collected from \\nthe employer or business, the trust fund recovery penalty \\nmay be imposed on all persons who are determined by \\nthe IRS to be responsible for collecting, accounting for, or \\npaying over these taxes, and who acted willfully in not do-\\ning so. The trust fund recovery penalty won't apply to any \\namount of trust fund taxes an employer holds back in an-\\nticipation of any credits they are entitled to.\\nA responsible person  can be an officer or employee \\nof a corporation, a partner or employee of a partnership, \\nan accountant, a volunteer director/trustee, or an employee of a sole proprietorship, or any other person or \\nentity that is responsible for collecting, accounting for, or \\npaying over trust fund taxes. A responsible person may \\nalso include one who signs checks for the business or oth-\\nerwise has authority to cause the spending of business \\nfunds.\\nWillfully  means voluntarily, consciously, and intention-\\nally. A responsible person acts willfully if the person knows \\nthe required actions of collecting, accounting for, or paying\",\n",
      "        \"metadata\": {\n",
      "          \"source\": \"data/p15.pdf\",\n",
      "          \"page\": 34\n",
      "        },\n",
      "        \"type\": \"Document\"\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(dumps(result, pretty=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up\n",
    "You have reached the end of this workshop. Following cell will delete all created resources.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'f90944fc-b29a-439b-8589-ec74e8906acf',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'f90944fc-b29a-439b-8589-ec74e8906acf',\n",
       "   'date': 'Wed, 05 Jun 2024 22:35:14 GMT',\n",
       "   'content-type': 'application/x-amz-json-1.0',\n",
       "   'content-length': '2',\n",
       "   'connection': 'keep-alive'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aoss_client.delete_collection(id=collection['createCollectionDetail']['id'])\n",
    "aoss_client.delete_access_policy(name=access_policy_name, type='data')\n",
    "aoss_client.delete_security_policy(name=encryption_policy_name, type='encryption')\n",
    "aoss_client.delete_security_policy(name=network_policy_name, type='network')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "Congratulations on completing this moduel on retrieval augmented generation! This is an important technique that combines the power of large language models with the precision of retrieval methods. By augmenting generation with relevant retrieved examples, the responses we recieved become more coherent, consistent and grounded. You should feel proud of learning this innovative approach. I'm sure the knowledge you've gained will be very useful for building creative and engaging language generation systems. Well done!\n",
    "\n",
    "In the above implementation of RAG based Question Answering we have explored the following concepts and how to implement them using Amazon Bedrock and it's LangChain integration.\n",
    "\n",
    "- Loading documents and generating embeddings to create a vector store\n",
    "- Retrieving documents to the question\n",
    "- Preparing a prompt which goes as input to the LLM\n",
    "- Present an answer in a human friendly manner\n",
    "- keep source knowledge up to date, and improve trust in our system by providing citations with every answer.\n",
    "\n",
    "### Take-aways\n",
    "- Experiment with different Vector Stores\n",
    "- Leverage various models available under Amazon Bedrock to see alternate outputs\n",
    "- Explore options such as persistent storage of embeddings and document chunks\n",
    "- Integration with enterprise data stores\n",
    "\n",
    "# Thank You"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
